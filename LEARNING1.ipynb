{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bximbo/Machine-Learning/blob/main/LEARNING1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vSSw65bJiwn"
      },
      "source": [
        "ALL ABOUT TENSORS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGhRSWYvmORu",
        "outputId": "e747c4db-8b0c-4068-ea13-014b12ef4633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.3597, 0.6195],\n",
            "        [0.5948, 0.3216]])\n",
            "tensor([[0.2189, 0.9775],\n",
            "        [0.9378, 0.1269]])\n",
            "torch.Size([2, 2])\n",
            "torch.Size([1, 4])\n",
            "tensor(0.4739)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "x = torch.rand(2, 2)\n",
        "y = torch.rand(2,2 )\n",
        "print(x )\n",
        "print(y  )\n",
        "z = torch.mul(x, y)\n",
        "print(z.size()  )\n",
        "#r = y + x\n",
        "# x.mul_(y)\n",
        "\n",
        "Q = x.view(1,4)\n",
        "print(Q.size())\n",
        "\n",
        "x = x.mean()\n",
        "\n",
        "print (x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR9LtDMgolG0",
        "outputId": "6da91a37-0508-4b3b-8e8c-053bcbd98c3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "u = torch.ones( 2, 2, dtype= torch.int)\n",
        "print(y.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UhaGauFjOYC",
        "outputId": "015c2459-8368-4e04-85ba-89c4da7b704e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.6154, 0.1268, 0.9877, 0.5839, 0.8550],\n",
            "        [0.3255, 0.1624, 0.7571, 0.3807, 0.8414],\n",
            "        [0.1010, 0.3759, 0.4483, 0.5821, 0.9878],\n",
            "        [0.5785, 0.2758, 0.6899, 0.3675, 0.8719],\n",
            "        [0.4122, 0.5525, 0.8559, 0.4879, 0.1096]])\n",
            "tensor([0.6154, 0.3255, 0.1010, 0.5785, 0.4122])\n",
            "tensor([0.1010, 0.3759, 0.4483, 0.5821, 0.9878])\n",
            "tensor([0.7571, 0.3807, 0.8414])\n",
            "tensor([0.3255, 0.1624])\n"
          ]
        }
      ],
      "source": [
        "i = torch.rand(5, 5 )\n",
        "print (i)\n",
        "print (i[:, 0]) #printed the first columns\n",
        "print (i[2, :]) #printed the 3rd row\n",
        "print (i [1,2: ])\n",
        "print (i [1,:2 ]) #print through row 2 and column before 2nd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oomOPG7Glu5q"
      },
      "source": [
        "TENSOR TO NUMPY & VICE VERSA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BiPxy3RAMHS",
        "outputId": "b5e8a8c3-059b-4ba5-adb1-0fd1e7fdd6a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "<class 'torch.Tensor'>\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([2., 2., 2., 2., 2.])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "print(type(a))\n",
        "\n",
        "#b = torch.ones(5) .numpy\n",
        "#print(type(b))\n",
        "\n",
        "c = a.numpy()\n",
        "print(c)\n",
        "print(type(c))\n",
        "\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(c)\n",
        "\n",
        "\n",
        "d = np.ones(5)\n",
        "print (d)\n",
        "print (type(d))\n",
        "\n",
        "#e = torch.from_numpy(d.astype(np.float32))\n",
        "#or\n",
        "e = torch.tensor( d.astype(np.float32))\n",
        "#without type is naturally uses float64\n",
        "\n",
        "\n",
        "print (e)\n",
        "print(type(e))\n",
        "\n",
        "e += 1\n",
        "print (e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA6kSsWMJY2N"
      },
      "source": [
        "AUTO GRAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHrlOa5xJYAi",
        "outputId": "5a4cbacb-ca30-4a67-db4c-cd2ca74da97a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0631, 0.9488, 0.2654],\n",
            "        [0.9281, 0.5603, 0.1408],\n",
            "        [0.3336, 0.8780, 0.2229]], requires_grad=True)\n",
            "tensor(2.4823, grad_fn=<MeanBackward0>)\n",
            "tensor([[0.1111, 0.1111, 0.1111],\n",
            "        [0.1111, 0.1111, 0.1111],\n",
            "        [0.1111, 0.1111, 0.1111]])\n",
            "tensor([[0.2720, 0.6984],\n",
            "        [0.4281, 0.2971]], requires_grad=True)\n",
            "tensor([[0.1000, 1.0000],\n",
            "        [1.0000, 0.1000]])\n",
            "tensor([[2.2720, 2.6984],\n",
            "        [2.4281, 2.2971]], grad_fn=<AddBackward0>)\n",
            "tensor([[2.2720, 2.6984],\n",
            "        [2.4281, 2.2971]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "aa = torch.rand(3, 3,  requires_grad = True )\n",
        "print(aa)\n",
        "\n",
        "bb = aa + 2\n",
        "bb= bb.mean()\n",
        "print(bb )\n",
        "\n",
        "bb.backward() # initializing direction for gradient (dbb/daa)\n",
        "print  (aa.grad)  #dbb/daa\n",
        "\n",
        "\n",
        "# Or.. especially if bb wasn't a scaler output\n",
        "\n",
        "cc = torch.rand(2,2, requires_grad = True)\n",
        "# cc = cc.mean()\n",
        "print (cc)\n",
        "\n",
        "qq = cc + 2\n",
        "\n",
        "zz = torch.tensor ([[0.1, 1.0], [1.0, 0.1]], dtype = torch.float)\n",
        "\n",
        "qq.backward(zz)\n",
        "print (cc.grad)\n",
        "\n",
        "\n",
        "# TO discontinue the grad\n",
        "# x.requires_grad_(False)\n",
        "# x.detach()\n",
        "# with torch.no_grad():\n",
        "\n",
        "#cc.requires_grad_(False)\n",
        "\n",
        "#rr = cc.detach()\n",
        "with torch.no_grad():\n",
        "  rr = cc + 2\n",
        "print (rr )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJZOI45I3Sg3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsCoHLOMm1qS"
      },
      "source": [
        "DUMMY TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJenFe6DmywF",
        "outputId": "3c441ea0-34b5-4afa-dbff-d3bd0af6a538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "weight = torch.ones(4, requires_grad = True)\n",
        "print(weight)\n",
        "\n",
        "for epoch in range (3):\n",
        "  model_outputs = (weight * 3).sum()\n",
        "\n",
        "  model_outputs.backward()\n",
        "\n",
        "  print(weight.grad)\n",
        "\n",
        "  weight.grad.zero_()\n",
        "\n",
        "\n",
        "\n",
        "#AT OPTIMIZER LEVEL AFTER IMPORT ... the below was for documentation\n",
        "\n",
        "optimizer = torch.optim.SGD(weight, lr = 0.01)\n",
        "\n",
        "optimizer.step()\n",
        "optimizer.zero_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsxGL1iDMk8y",
        "outputId": "990ae519-84ff-48d9-b97b-747a49a4f65b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]])\n",
            "tensor([[3., 3.],\n",
            "        [3., 3.]])\n",
            "tensor([[3., 3.],\n",
            "        [3., 3.]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "weights = torch.ones(2,2 , requires_grad = True)\n",
        "\n",
        "for epoch in range(3):\n",
        "  output = (weights * 3).sum()\n",
        "  # weights.requires_grad(False)\n",
        "\n",
        "\n",
        "  output.backward()\n",
        "  print(weights.grad)\n",
        "\n",
        "  weights.grad.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUpYthFqU96d"
      },
      "source": [
        "BACKWARD PROBATION (FULL CIRCLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUkbekIgU1ai",
        "outputId": "6e384a9c-dad3-4878-98fc-1bf61c050f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_hat: tensor(1., grad_fn=<MulBackward0>)\n",
            "Loss: tensor(1., grad_fn=<PowBackward0>)\n",
            "dLoss/dWeight gradient: tensor(-2.)\n"
          ]
        }
      ],
      "source": [
        "# initializing\n",
        "\n",
        "import torch\n",
        "\n",
        "# declaring maybe variables\n",
        "\n",
        "x = torch.tensor(1.0)  #maybe an initial input asin something to use to train or test\n",
        "y = torch.tensor(2.0)  #maybe a second input asin something to use to train or test i believe this is the second input. though either it's entering the second node as an output of the first node or it is part of the input entering a different node on the same layer\n",
        "\n",
        "w = torch.tensor(1.0,  requires_grad = True)  #initial weight\n",
        "\n",
        "#forward pass & compute loss\n",
        "\n",
        "y_hat = x * w\n",
        "loss = (y_hat - y) ** 2\n",
        "\n",
        "print(f'y_hat:', y_hat)\n",
        "print(f'Loss:', loss)\n",
        "\n",
        "# second step wpuld be to calculate local gradient but that is done by the program already\n",
        "\n",
        "#Backward pass: compute gradient\n",
        "\n",
        "loss.backward()\n",
        "print(f'dLoss/dWeight gradient:', w.grad)\n",
        "\n",
        "\n",
        "#run for each epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnTYi_z0gF-5"
      },
      "source": [
        "#TRAINING MANUALLY (LOGISTICS REGRESSION I BELIEVE) using NUMPY\n",
        "\n",
        "* Prediction: Manually\n",
        "* Gradients Computations: Manually\n",
        "* Loss Computation: Manually\n",
        "* Parameter updates(Optimization step): Manually\n",
        "\n",
        "Note that over my learning phases i will come back to keep optimizing this code to maximize plug and play performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT4yMlysgFel",
        "outputId": "64820290-a235-4034-a2b2-1a1b78a2542c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction before training, at f(5) =  0.000\n",
            "Epoch 1: Weight: 1.200   loss: 30.00000000\n",
            "Epoch 2: Weight: 1.680   loss: 4.79999924\n",
            "Epoch 3: Weight: 1.872   loss: 0.76800019\n",
            "Epoch 4: Weight: 1.949   loss: 0.12288000\n",
            "Epoch 5: Weight: 1.980   loss: 0.01966083\n",
            "Epoch 6: Weight: 1.992   loss: 0.00314574\n",
            "Epoch 7: Weight: 1.997   loss: 0.00050331\n",
            "Epoch 8: Weight: 1.999   loss: 0.00008053\n",
            "Epoch 9: Weight: 1.999   loss: 0.00001288\n",
            "Epoch 10: Weight: 2.000   loss: 0.00000206\n",
            "Epoch 11: Weight: 2.000   loss: 0.00000033\n",
            "Prediction after training at f(5) =  10.000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# f = w * x\n",
        "\n",
        "# f = 2 * x\n",
        "\n",
        "X = torch.tensor([1, 2, 3, 4], dtype = torch.float32)   #training data\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype = torch.float32)   #training data\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "#Model Prediction\n",
        "def forward(x):\n",
        "  return w  * x\n",
        "\n",
        "#loss = MSE\n",
        "def loss( y, y_predicted ):\n",
        "  return ((y_predicted - y)**2).mean()\n",
        "\n",
        "#Calculate gradient\n",
        "# MSE = 1/N (w*x - y) ** 2\n",
        "# dLoss/dWeight = 1/N 2x * (w*x - y)\n",
        "def gradient(y, x, y_predicted):\n",
        "  return (np.dot(2*x, y_predicted - y)).mean()\n",
        "\n",
        "\n",
        "print(f'Prediction before training, at f(5) =  {forward(5):.3f}')\n",
        "\n",
        "#TRAINING\n",
        "\n",
        "learning_rate = 0.01\n",
        "num_epoch = 11\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "\n",
        "  # Prediction or forward pass\n",
        "  y_pred = forward(X)\n",
        "\n",
        "  #loss\n",
        "  losses = loss( Y,  y_pred)\n",
        "\n",
        "  #gradient = backward pass\n",
        "  dw = gradient(Y, X, y_pred)\n",
        "\n",
        "  # Parameter update weights with gradients\n",
        "  w -= learning_rate * dw\n",
        "\n",
        "  if epoch % 1 == 0:\n",
        "    print(f'Epoch {epoch+1}: Weight: {w :.3f}   loss: {losses:.8f}')\n",
        "\n",
        "print(f'Prediction after training at f(5) =  {forward(5):.3f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx8H1Kvdb6f4"
      },
      "source": [
        "#AUTOMATING THE TRAINING using PYTORCH\n",
        "\n",
        "* Prediction: Model function or custom architecture\n",
        "* Gradients Computations: Autograd\n",
        "* Loss Computation: MSELoss function\n",
        "* Parameter updates(Optimization step): optimizer function with manually ending the grad\n",
        "\n",
        "//Note that over my learning phases i will come back to keep optimizing this code to maximize plug and play performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnvw4_r5b05C",
        "outputId": "213c1f9b-c68d-43cb-f36e-2eac7b944917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4 1\n",
            "Prediction before training, at f(5) =  4.772\n",
            "Epoch 1: Weight: 1.074  loss: 7.85537529\n",
            "Epoch 11: Weight: 1.719  loss: 0.23842786\n",
            "Epoch 21: Weight: 1.827  loss: 0.03931081\n",
            "Epoch 31: Weight: 1.848  loss: 0.03223015\n",
            "Epoch 41: Weight: 1.855  loss: 0.03023019\n",
            "Epoch 51: Weight: 1.860  loss: 0.02846742\n",
            "Epoch 61: Weight: 1.864  loss: 0.02681035\n",
            "Epoch 71: Weight: 1.868  loss: 0.02524987\n",
            "Epoch 81: Weight: 1.872  loss: 0.02378018\n",
            "Epoch 91: Weight: 1.876  loss: 0.02239608\n",
            "Prediction after training at f(5) =   9.751\n"
          ]
        }
      ],
      "source": [
        "# TO-DO LIST\n",
        "# 1. Design the model (inputs & outputs sizes, forward pass)\n",
        "# 2. compute loss and optimizer\n",
        "# 3. Training loop\n",
        "#    - Forward pass: Compute Prediction\n",
        "#    - Backward pass: Calculate gradient\n",
        "#    - Update parameters\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# f = w * x\n",
        "\n",
        "# f = 2 * x\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype = torch.float32)   #training data\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype = torch.float32)   #training data\n",
        "\n",
        "test_input =  torch.tensor([5], dtype = torch.float32)   #test sample\n",
        "\n",
        "sample_size, feature_size = X.shape\n",
        "print(sample_size, feature_size)\n",
        "\n",
        "n_inputs = feature_size\n",
        "n_outputs = feature_size\n",
        "\n",
        "#Model Prediction\n",
        "#model = nn.Linear(n_inputs, n_outputs).         This is an inbuilt no layer function\n",
        "# Orrrrrrrr\n",
        "\n",
        "class bimbo(nn.Module):\n",
        "  def __init__(self, inputs_dim, outputs_dim ):\n",
        "    super(bimbo, self).__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(inputs_dim, outputs_dim)\n",
        "\n",
        "  def forward  (self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = bimbo(n_inputs, n_outputs)\n",
        "\n",
        "\n",
        "print(f'Prediction before training, at f(5) =  {model(test_input).item():.3f}')\n",
        "\n",
        "#TRAINING\n",
        "\n",
        "learning_rate = 0.01\n",
        "num_epoch = 100\n",
        "\n",
        "#loss = MSE\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "\n",
        "  # Prediction or forward pass\n",
        "  y_pred = model(X)\n",
        "\n",
        "  #loss\n",
        "  losses = loss( Y,  y_pred)\n",
        "\n",
        "  #gradient = backward pass\n",
        "  losses.backward()    #dLosses/dWeights\n",
        "\n",
        "\n",
        "  # Parameter updates (weights in model) with gradient\n",
        "  optimizer.step()     #this will serve as the optimizer step\n",
        "\n",
        "  # Zero gradient\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10  == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'Epoch {epoch+1}: Weight: {w[0][0]:.3f}  loss: {losses:.8f}')\n",
        "\n",
        "print(f'Prediction after training at f(5) =   {model(test_input).item():.3f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzvesO3Jo4xS"
      },
      "source": [
        "#PRACTICING A LINEAR REGRESSION CODE FROM ALL I HAVE LEARNED\n",
        "So help me God"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "rcdpHpX7o4SV",
        "outputId": "49cde862-9b5d-4d54-e4a2-0bc2e200f052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 100000 Loss: 332.56756592 \n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TO-DO LIST\n",
        "# 1. Import the necessariesss\n",
        "# 2. Data preping x converting\n",
        "# 3. Design the model (inputs & outputs sizes, forward pass)\n",
        "# 4. compute loss and optimizer\n",
        "# 5. Training loop\n",
        "#    - Forward pass: Compute Prediction\n",
        "#    - Backward pass: Calculate gradient\n",
        "#    - Update parameters\n",
        "# 6. Evalaute (This time just using graph(PLOT))\n",
        "\n",
        "#1.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np          #For the necessary data transformations\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#2.\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples = 100, n_features = 1, noise = 20, random_state = 1)\n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features  = X.shape\n",
        "\n",
        "#3.\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "\n",
        "#model = nn.Linear(input_size, output_size)\n",
        "\n",
        "\n",
        "#Orrrrrrrrrrrrrrr\n",
        "class bimbo(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(bimbo,self).__init__()\n",
        "    # define layers\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = bimbo(input_size, output_size)\n",
        "\n",
        "#4.\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "#5.\n",
        "num_epoch = 100000\n",
        "for epoch in range(num_epoch):\n",
        "  #forward pass\n",
        "  y_predicted = model(X)\n",
        "\n",
        "  #loss\n",
        "  loss = criterion (y_predicted, y)\n",
        "\n",
        "  #backward\n",
        "  loss.backward()\n",
        "\n",
        "  #update\n",
        "  optimizer.step()\n",
        "  #end gradient to avoid sums\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % 100000 == 0:\n",
        "    print(f'Epoch: {epoch+1} Loss: {loss.item():.8f} ')\n",
        "\n",
        "\n",
        "#6.\n",
        "predicted = model(X).detach().numpy()\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted,  'b')\n",
        "plt.show()\n",
        "#print(f'X_numpy: {X_numpy}')\n",
        "#print(f'predicted: {predicted}')\n",
        "#print(f'y_numpy: {y_numpy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqXFwndV7hMC"
      },
      "source": [
        "#PRACTICING A LOGISTIC REGRESSION CODE FROM ALL I HAVE LEARNED\n",
        "So help me God"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBloM51x7fF9",
        "outputId": "41f7d914-0744-49c4-aa55-5522ecbaf291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 20/200 loss: 0.47832\n",
            "epoch: 40/200 loss: 0.36693\n",
            "epoch: 60/200 loss: 0.30890\n",
            "epoch: 80/200 loss: 0.27222\n",
            "epoch: 100/200 loss: 0.24637\n",
            "epoch: 120/200 loss: 0.22688\n",
            "epoch: 140/200 loss: 0.21148\n",
            "epoch: 160/200 loss: 0.19891\n",
            "epoch: 180/200 loss: 0.18839\n",
            "epoch: 200/200 loss: 0.17944\n",
            "Accuracy: 0.89\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n",
            "tensor([[-0.7085,  0.1531, -0.7017,  ..., -0.5107,  0.5043,  0.2811],\n",
            "        [-0.9578, -2.2431, -0.9696,  ..., -1.0445, -1.3419, -0.3880],\n",
            "        [-0.4850, -0.6859, -0.3837,  ...,  0.2937,  0.5457,  1.0246],\n",
            "        ...,\n",
            "        [-0.2501, -1.0694, -0.3051,  ..., -0.2239, -1.4462, -1.1865],\n",
            "        [-0.2042,  0.0625, -0.2593,  ...,  0.0175, -0.0284, -0.5634],\n",
            "        [ 3.8046,  1.6058,  3.9461,  ...,  2.2410, -0.4304, -0.5335]])\n"
          ]
        }
      ],
      "source": [
        "# TO-DO LIST\n",
        "# 1. Import the necessariesss\n",
        "# 2. Data preping\n",
        "# 3. Scale before conversion\n",
        "# 4. Design the model (inputs & outputs sizes, forward pass)\n",
        "# 5. compute loss and optimizer\n",
        "# 6. Training loop\n",
        "#    - Forward pass: Compute Prediction\n",
        "#    - Backward pass: Calculate gradient\n",
        "#    - Update parameters\n",
        "# 7. Evalaute (This time just using graph)\n",
        "\n",
        "\n",
        "#1.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#2.\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "#print(n_samples, n_features )\n",
        "\n",
        "#split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 1234)\n",
        "\n",
        "#3.\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "#4.\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "#Conversion\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "#5.\n",
        "# f = wx + b, sigmoid at the end to return a value between 0 and 1\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "\n",
        "  def forward (self, x):\n",
        "     y_predicted = torch.sigmoid(self.linear(x))\n",
        "     return  y_predicted\n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "#6.\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
        "\n",
        "num_epoch = 200\n",
        "for epoch in range (num_epoch):\n",
        "  #forward pass\n",
        "  y_predicted = model(X_train)\n",
        "\n",
        "  #loss\n",
        "  loss = criterion(y_predicted, y_train)\n",
        "\n",
        "  #Backward\n",
        "  loss.backward()\n",
        "\n",
        "  #optimizer\n",
        "  optimizer.step()\n",
        "\n",
        "  #zero gradients\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if (epoch+1) % 20 == 0:\n",
        "    #Use this to pick the weights\n",
        "    #[w, b] = model.parameters()\n",
        "    #print(f'epoch: {epoch+1}/{num_epoch} Weight: {w[0][0]:.3f} loss: {loss.item():.5f}')\n",
        "    print(f'epoch: {epoch+1}/{num_epoch} loss: {loss.item():.5f}')\n",
        "\n",
        "\n",
        "#7.\n",
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round()             #to provide a boundary for the classification to give 1 or 0 class\n",
        "  accuracy = y_predicted_cls.eq(y_test).sum() /  float(y_test.shape[0]) # y_predicted.eq(y_test).sum() / y.test.size()\n",
        "  print(f'Accuracy: {accuracy:.2f}')\n",
        "  print(y_predicted.round()  )\n",
        "  print(X_test)\n",
        "\n",
        "\n",
        "#8. trying plot (i will wait till i learn more)\n",
        "#y_predicted = model(X_train).detach().numpy()\n",
        "#plt.plot( y_train, 'ro')\n",
        "#plt.plot( y_predicted, 'b')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioXXfVladjZS"
      },
      "source": [
        "DATA SETS X DATA LOADER - FOR EXPLANATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyQPPHczdjH-"
      },
      "outputs": [],
      "source": [
        "#1.\n",
        "data = numpy.loadtxt('wine.csv')\n",
        "#training loop\n",
        "for epoch in range(1000):\n",
        "  x, y = data\n",
        "  #forward + backward + weight updates\n",
        "\n",
        "\n",
        "#2.\n",
        "#training loop\n",
        "for epoch in range(1000):\n",
        "  #loop for all batches\n",
        "  for i in range(total_batches):\n",
        "    x_batch, y_batch = . . .\n",
        "\n",
        "# --> use DataSet and DataLoader to load.wine.csv\n",
        "\n",
        "\n",
        "#3.\n",
        "'''\n",
        "epoch =. 1 forward and backward pass for ALL training samples\n",
        "\n",
        "batch_size = number of training samples in one forward & backward pass\n",
        "\n",
        "number of iterations = number of passes, each pass using [batch_size] number of samples\n",
        "\n",
        "e.g. 100 samples, batch_size = 20 --> 100/20 = 5 iterations for 1 epoch\n",
        "'''\n",
        "\n",
        "\n",
        "#start\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyKlF0qhzz_j"
      },
      "source": [
        "#DATA SETS X DATA LOADER - Practice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f6T1UP_z4YS",
        "outputId": "0505d561-d6e9-40d4-b655-a0c7f54e66e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total samples: 178, Number of iterations: 45\n",
            "Epoch 1/2 steps 5/45  inputs torch.Size([4, 13])\n",
            "Epoch 1/2 steps 10/45  inputs torch.Size([4, 13])\n",
            "Epoch 1/2 steps 15/45  inputs torch.Size([4, 13])\n",
            "Epoch 1/2 steps 20/45  inputs torch.Size([4, 13])\n",
            "Epoch 1/2 steps 25/45  inputs torch.Size([4, 13])\n",
            "Epoch 1/2 steps 30/45  inputs torch.Size([4, 13])\n",
            "Epoch 1/2 steps 35/45  inputs torch.Size([4, 13])\n",
            "Epoch 1/2 steps 40/45  inputs torch.Size([4, 13])\n",
            "Epoch 1/2 steps 45/45  inputs torch.Size([2, 13])\n",
            "Epoch 2/2 steps 5/45  inputs torch.Size([4, 13])\n",
            "Epoch 2/2 steps 10/45  inputs torch.Size([4, 13])\n",
            "Epoch 2/2 steps 15/45  inputs torch.Size([4, 13])\n",
            "Epoch 2/2 steps 20/45  inputs torch.Size([4, 13])\n",
            "Epoch 2/2 steps 25/45  inputs torch.Size([4, 13])\n",
            "Epoch 2/2 steps 30/45  inputs torch.Size([4, 13])\n",
            "Epoch 2/2 steps 35/45  inputs torch.Size([4, 13])\n",
            "Epoch 2/2 steps 40/45  inputs torch.Size([4, 13])\n",
            "Epoch 2/2 steps 45/45  inputs torch.Size([2, 13])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineSet(Dataset):\n",
        "  def __init__(self):\n",
        "    #data loading\n",
        "    xy = np.loadtxt('/content/wine (1).csv', delimiter = \",\", dtype = np.float32, skiprows = 1)\n",
        "    self.x = torch.from_numpy(xy[:, 1:])\n",
        "    self.y = torch.from_numpy(xy[:, [0]]) #n_samples, 1\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #dataset[0]\n",
        "    return self.x[index],self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    #len(Dataset)\n",
        "    return self.n_samples\n",
        "\n",
        "\n",
        "#just loading the dataset\n",
        "'''\n",
        "dataset = WineSet()\n",
        "first_data = dataset[1]\n",
        "print('first_dataset', first_data)\n",
        "features,labels = first_data\n",
        "print(features, labels)\n",
        "'''\n",
        "\n",
        "#with dataloader\n",
        "'''\n",
        "dataset = WineSet()\n",
        "dataloader = DataLoader(dataset= dataset, batch_size= 4, shuffle= True, num_workers= 2)\n",
        "\n",
        "datatiter = iter(dataloader)\n",
        "#data = datatiter.next()\n",
        "for datatiter in dataloader:\n",
        "  features, labels = datatiter\n",
        "  print(features, labels)\n",
        "'''\n",
        "\n",
        "#Dummy training loop\n",
        "dataset = WineSet()\n",
        "dataloader = DataLoader(dataset= dataset, batch_size= 4, shuffle= True, num_workers= 2)\n",
        "\n",
        "num_epochs = 2\n",
        "sampless = len(dataset)\n",
        "n_iterations = math.ceil(sampless/4)\n",
        "print(f'Total samples: {sampless}, Number of iterations: {n_iterations}')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "   for i, (inputs, labels) in enumerate(dataloader):\n",
        "    #forward, backward, update\n",
        "    if (1+i) % 5 == 0:\n",
        "      print(f'Epoch {epoch+1}/{num_epochs} steps {i+1}/{n_iterations}  inputs {inputs.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsEi1KCzl-g-",
        "outputId": "d537c349-30b8-4c61-f81f-3051a93230cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 4, 13, 28, 27, 18])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.convolve((1,2,3), (4,5,6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCSzr8sQxRla"
      },
      "source": [
        "#Dataset Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqvqgxdyxQFG",
        "outputId": "61ccae55-930e-437b-ff6c-398524689758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
            "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
            "        4.2600e+03])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "#import torch\n",
        "#import torchvision\n",
        "\n",
        "\n",
        "#dataset = torchvision.datasets.MNIST(root = './data', transform=torchvision.ToTensor())\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class WineSet(Dataset):\n",
        "\n",
        "  def __init__(self, transform  = None):\n",
        "    #data loading\n",
        "    xy = np.loadtxt('/content/wine (1).csv', delimiter = \",\", dtype = np.float32, skiprows = 1)\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "    #note that there is no conversion to tensors here\n",
        "    self.x = xy[:, 1:]\n",
        "    self.y = xy[:, [0]] #n_samples, 1\n",
        "\n",
        "    self.transform = transform\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    #dataset[0]\n",
        "    sample =  self.x[index],self.y[index]\n",
        "\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    #len(Dataset)\n",
        "    return self.n_samples\n",
        "\n",
        "class ToTensor: #transform class\n",
        "  def __call__ (self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "\n",
        "class MulTransform:\n",
        "  def __init__(self, factor):\n",
        "    self. factor = factor\n",
        "\n",
        "  def __call__(self, sample):\n",
        "    inputs, target = sample\n",
        "    inputs *= self. factor\n",
        "    return inputs, target\n",
        "\n",
        "\n",
        "#dataset = WineSet(transform = ToTensor())\n",
        "dataset = WineSet(transform = None)\n",
        "firsts_data = dataset[0]\n",
        "features, labels =  firsts_data\n",
        "print(features)\n",
        "print(type(features), type(labels) )\n",
        "\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineSet(transform = composed)\n",
        "firsts_data = dataset[0]\n",
        "features, labels =  firsts_data\n",
        "print(features)\n",
        "print(type(features), type(labels) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TRANSfprmation On Images\n",
        "'''\n",
        "# TRANSfprmation On Images\n",
        "\n",
        "CenterCrop, Grayscale, Pad, RandomAffine\n",
        "RandomCrop, RandomHorizontalFlip, RandomRotation\n",
        "Resize, Scale\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_2pzk1rJDJM"
      },
      "source": [
        "#SoftMAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGp0qC6nIs_x",
        "outputId": "3c5b9745-f83b-434b-838b-03133071f1c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "softmax numpy = [0.65900114 0.24243297 0.09856589]\n",
            "softmax pytorch = [0.7, 0.2, 0.1]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "  return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0,1.0,0.1])\n",
        "outputs = softmax(x)\n",
        "print(f'softmax numpy = {outputs}')\n",
        "\n",
        "\n",
        "#Using pytorch\n",
        "x = torch.tensor([2.0,1.0,0.1])\n",
        "outputs = torch.softmax(x, dim = 0)\n",
        "\n",
        "#print(f'softmax pytorch = {outputs:}')\n",
        "formatted_outputs = ', '.join([f'{value:.1f}' for value in outputs]) #Approximation step\n",
        "print(f'softmax pytorch = [{formatted_outputs}]')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czXUxq_e0Lw1"
      },
      "source": [
        "#Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPFkvnZy0Lbu",
        "outputId": "4b3b1f23-10aa-48e9-8947-b0caf4ec84f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss1 numpy: 0.3567\n",
            "Loss2 numpy: 2.3026\n",
            "---------------------\n",
            "Loss1 pytorch: 0.163\n",
            "Loss2 pytorch: 1.655\n",
            "---------------------\n",
            "predictions1: tensor([2.1000, 8.0000, 3.0000]) indicies1: tensor([2, 0, 1])\n",
            "predictions2: tensor([2.1000, 2.1000, 3.0000]) indicies2: tensor([0, 2, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def cross_entropy (actual, predicted):\n",
        "  loss = -np.sum(actual * np.log(predicted))\n",
        "  return loss # / float(predicted.shape[0])\n",
        "\n",
        "#Or\n",
        "'''\n",
        "def cross_entropy (actual, predicted):\n",
        "  return -np.sum(actual * np.log(predicted))\n",
        "  #return loss # / float(predicted.shape[0])\n",
        "'''\n",
        "\n",
        "# Y must be one hot encoded (means wherever 1 is, the highest probability should be there. Hence, a good prediction)\n",
        "# if class 0: [1 0 0]\n",
        "# if class 1: [0 1 0]\n",
        "# if class 2: [0 0 1]\n",
        "Y = np.array ( [1, 0, 0])\n",
        "\n",
        "# y_pred has probabilities\n",
        "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "l1 = cross_entropy(Y, Y_pred_good)\n",
        "l2 = cross_entropy(Y, Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "#Using pytorch\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "# n_samples x n_classes = 3 x3\n",
        "Y_pred_good = torch.tensor([[0.1, 1.0, 2.1], [8.0, 1.0, 0.1], [0.1, 3.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[2.1, 1.0, 0.1], [0., 1.0, 2 .1], [0.1, 3.0, 0.1]])\n",
        "\n",
        "l3 = loss(Y_pred_good, Y)\n",
        "l4 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(f'---------------------')\n",
        "print(f'Loss1 pytorch: {l3.item():.3f}')\n",
        "print(f'Loss2 pytorch: {l4.item():.3f}')\n",
        "\n",
        "predictions1, indicies1 = torch.max(Y_pred_good, 1)\n",
        "predictions2, indicies2  = torch.max(Y_pred_bad, 1)\n",
        "print(f'---------------------')\n",
        "print(f'predictions1: {predictions1} indicies1: {indicies1}')\n",
        "print(f'predictions2: {predictions2} indicies2: {indicies2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjK1vspMDP1A"
      },
      "source": [
        "#Multi Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpChAFDXnziX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Multiclass problem\n",
        "class NeuralNet2(nn.Module) :\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet2, self)._init_()\n",
        "    self.linearl = nn. Linear (input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.linear2 = nn. Linear (hidden_size, num_classes)\n",
        "\n",
        "  def forward (self, x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu (out)\n",
        "    out = self.linear2 (out)\n",
        "    # no softmax at the end\n",
        "    return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn. CrossEntropyLoss () # (applies Softmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbok3mKeD52A"
      },
      "source": [
        "#Binary class\n",
        "\n",
        "#Note: Methods of using Activation functions are showed here\n",
        "\n",
        "Most popular activation\n",
        "functions\n",
        "\n",
        "1. Step function\n",
        "2. Sigmoid\n",
        "3. TnH\n",
        "4. ReLU\n",
        "5. Leaky ReLU\n",
        "6. Softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qV3A63KDYHa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Binary classification\n",
        "\n",
        "# option 1 (use activation functions seperately in forward pass)\n",
        "class NeuralNet1(nn.Module) :\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super (NeuralNet1, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    #Others are written as...\n",
        "    '''\n",
        "    nn.Sigmoid\n",
        "    nn.Softmax\n",
        "    nn.TanH\n",
        "    nn.LeakyReLU\n",
        "    '''\n",
        "    self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward (self, x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.linear2 (out)\n",
        "    # sigmoid at the end\n",
        "    y_pred = torch. sigmoid (out)\n",
        "    return y_pred\n",
        "\n",
        "# option 2 (use activation functions directly in forward pass)\n",
        "class NeuralNet(nn.Module) :\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super (NeuralNet, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "    self.linear2 = nn.Linear (hidden_size, 1)\n",
        "\n",
        "  def forward (self, x):\n",
        "    out = torch.relu(self.linear1(x))\n",
        "    out = torch.sigmoid(self.linear2(out))\n",
        "\n",
        "    #Others are written as...\n",
        "    '''\n",
        "    F.reLU()     #some have to be imported from the torch.nn.functional\n",
        "    F.leaky_relu( )\n",
        "    torch.softmax\n",
        "    torch.tanh\n",
        "    '''\n",
        "    return out\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvMQ8lliJ5JH"
      },
      "source": [
        "#Feed-Forward Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "P-wBjbJ-J3qH",
        "outputId": "b031be43-3af6-4329-e9b4-4bee6e504adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
            "epoch 1/2  step 100/600  loss: 0.349\n",
            "epoch 1/2  step 200/600  loss: 0.413\n",
            "epoch 1/2  step 300/600  loss: 0.317\n",
            "epoch 1/2  step 400/600  loss: 0.309\n",
            "epoch 1/2  step 500/600  loss: 0.307\n",
            "epoch 1/2  step 600/600  loss: 0.207\n",
            "epoch 2/2  step 100/600  loss: 0.171\n",
            "epoch 2/2  step 200/600  loss: 0.279\n",
            "epoch 2/2  step 300/600  loss: 0.135\n",
            "epoch 2/2  step 400/600  loss: 0.140\n",
            "epoch 2/2  step 500/600  loss: 0.176\n",
            "epoch 2/2  step 600/600  loss: 0.186\n",
            "accuracy: 95.07\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#1. Import\n",
        "#2. MNIST\n",
        "#3. DataLoader, Transformation\n",
        "#4. Multilayer Neural Net, activation function\n",
        "#5. Loss and Optimizer\n",
        "#6. Training Loop (batch training)\n",
        "#7. Model evaluation\n",
        "#8. GPU support\n",
        "\n",
        "#1.\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Device configuration\n",
        "device = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Hyper parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 100\n",
        "num_classes =  10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "#2. MNIST\n",
        "training_dataset = torchvision.datasets.MNIST(root = './data' , train =True,  transform=transforms.ToTensor(), download=True)\n",
        "testing_dataset = torchvision.datasets.MNIST(root = './data' , train =False,  transform=transforms.ToTensor())\n",
        "\n",
        "#3.\n",
        "training_loader = torch.utils.data.DataLoader(dataset = training_dataset, batch_size = batch_size, shuffle = True)\n",
        "testing_loader = torch.utils.data.DataLoader(dataset = testing_dataset, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "#Transformations\n",
        "examples = iter(testing_loader)\n",
        "samples, labels = next(examples)\n",
        "print(samples.shape, labels.shape)\n",
        "\n",
        "#plot\n",
        "for i in range(6):\n",
        "  plt.subplot (2, 3, i+1)\n",
        "  plt.imshow(samples [i] [0], cmap='gray')\n",
        "  #plt.show()\n",
        "\n",
        "#4.\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNet, self) .__init__()\n",
        "    self.input_size = input_size\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "#5.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#6.\n",
        "n_total_steps = len(training_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(training_loader):\n",
        "    #100, 1, 28, 28\n",
        "    #100, 784\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    #forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    #Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (i+1) % 100 == 0:\n",
        "      print (f'epoch {epoch+1}/{num_epochs}  step {i+1}/{n_total_steps}  loss: {loss.item():.3f}')\n",
        "\n",
        "\n",
        "\n",
        "#test\n",
        "with  torch.no_grad():\n",
        "  no_correct = 0\n",
        "  no_samples = 0\n",
        "  for images, labels in testing_loader:\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    #value, index\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    no_samples += labels.shape[0]\n",
        "    no_correct += (predictions == labels).sum().item()\n",
        "\n",
        "  accuracy = 100.0 * no_correct / no_samples\n",
        "  print(f'accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ho6y998wTJmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xavs9sydUQ7B"
      },
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "  num = eval(input('Enter a number: '))\n",
        "  print ('The square of your number is', num*num)\n",
        "  print('The loop is now done.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "y_pxWG953hYe",
        "outputId": "604dcd5f-a73c-41b5-b0c9-0481fcaf49c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.3181\n",
            "Epoch [1/2], Step [200/600], Loss: 0.2424\n",
            "Epoch [1/2], Step [300/600], Loss: 0.2264\n",
            "Epoch [1/2], Step [400/600], Loss: 0.1867\n",
            "Epoch [1/2], Step [500/600], Loss: 0.2833\n",
            "Epoch [1/2], Step [600/600], Loss: 0.1763\n",
            "Epoch [2/2], Step [100/600], Loss: 0.1028\n",
            "Epoch [2/2], Step [200/600], Loss: 0.1009\n",
            "Epoch [2/2], Step [300/600], Loss: 0.0859\n",
            "Epoch [2/2], Step [400/600], Loss: 0.0618\n",
            "Epoch [2/2], Step [500/600], Loss: 0.1878\n",
            "Epoch [2/2], Step [600/600], Loss: 0.0397\n",
            "Accuracy of the network on the 10000 test images: 97.11 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run data/models on an Apple Silicon GPU, use the PyTorch device name \"mps\" with .to(\"mps\"). MPS stands for Metal Performance Shaders, Metal is Apple's GPU framework."
      ],
      "metadata": {
        "id": "smGBmMVQGLYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Set the device\n",
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "\n",
        "# Create data and send it to the device\n",
        "x = torch.rand(size=(3, 4)).to(device)\n",
        "x"
      ],
      "metadata": {
        "id": "0o1KkPM9GHf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Steps I uploaded in my environment (Just in case)"
      ],
      "metadata": {
        "id": "eJcP8DDRkdjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip3 install torch torchvision torchaudio\n",
        "conda install jupyter pandas numpy matplotlib scikit-learn tqdm\n",
        "!pip install PyDrive     #For google drive access\n",
        "!pip install roboflow     #for roboflow\n"
      ],
      "metadata": {
        "id": "qJk_ldrQkedU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCR3RwCP9F7GRH2qOpD9K8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}